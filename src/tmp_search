use crate::book::{self, sample_books};
use std::collections::HashMap;

fn vectorize_books(documents: Vec<book::Book>) -> Vec<HashMap<String, f32>> {
    let mut all_word_count: Vec<HashMap<String, i32>> = Vec::new();
    
    // Collect term frequencies
    for doc in documents.iter() {
        let mut word_count = HashMap::new();
        for word in doc.title.split_whitespace() {
            *word_count.entry(word.to_lowercase()).or_insert(0) += 1;
        }
        for word in doc.author.split_whitespace() {
            *word_count.entry(word.to_lowercase()).or_insert(0) += 1;
        }
        for word in &doc.tags {
            *word_count.entry(word.to_lowercase()).or_insert(0) += 1;
        }
        all_word_count.push(word_count);
    }

    println!("{:?}", all_word_count);

    // Calculate the document frequency for IDF calculation
    let mut document_frequency: HashMap<String, i32> = HashMap::new();
    for word_count in &all_word_count {
        for word in word_count.keys() {
            *document_frequency.entry(word.clone()).or_insert(0) += 1;
        }
    }

    let total_documents = documents.len() as f32;
    let mut tfidf_vectors = Vec::new();

    // Calculate TF-IDF vectors
    for word_count in all_word_count {
        let mut tfidf_vector = HashMap::new();
        for (word, count) in word_count {
            let tf = count as f32;
            let idf = (total_documents / *document_frequency.get(&word).unwrap_or(&1) as f32).ln();
            tfidf_vector.insert(word, tf * idf);
        }
        tfidf_vectors.push(tfidf_vector);
    }

    tfidf_vectors
}

fn cosine_similarity(vec1: &HashMap<String, f32>, vec2: &HashMap<String, f32>) -> f32 {
    let dot_product: f32 = vec1.iter().filter_map(|(k, v1)| {
        vec2.get(k).map(|v2| v1 * v2)
    }).sum();

    let magnitude1: f32 = vec1.values().map(|v| v * v).sum::<f32>().sqrt();
    let magnitude2: f32 = vec2.values().map(|v| v * v).sum::<f32>().sqrt();

    if magnitude1 == 0.0 || magnitude2 == 0.0 {
        return 0.0;
    }

    dot_product / (magnitude1 * magnitude2)
}

pub fn rank_books_by_search_string(search_string: &str) -> Vec<(book::Book, f32)> {
    let books: Vec<book::Book> = sample_books();
    let book_vectors = vectorize_books(books.clone());

    // Vectorize the search string
    let mut search_vector = HashMap::new();
    for word in search_string.split_whitespace() {
        *search_vector.entry(word.to_lowercase()).or_insert(0) += 1;
    }

    let total_documents = books.len() as f32;
    let mut search_tfidf = HashMap::new();
    for (word, count) in search_vector {
        let tf = count as f32;
        let idf = (total_documents / 1.0).ln(); // Placeholder for IDF, can improve based on book data
        search_tfidf.insert(word, tf * idf);
    }

    // Calculate cosine similarity and rank
    let mut ranked_books: Vec<(book::Book, f32)> = books.into_iter()
        .zip(book_vectors.into_iter())
        .map(|(book, vector)| (book, cosine_similarity(&search_tfidf, &vector)))
        .collect();

    // Sort by similarity score in descending order
    ranked_books.sort_by(|(_, score1), (_, score2)| score2.partial_cmp(score1).unwrap());

    ranked_books
}

pub fn test() {
    let search_string = "prog";
    let ranked_books = rank_books_by_search_string(search_string);
    
    for (book, score) in ranked_books {
        println!("{:?} - Similarity Score: {}", book.title, score);
    }
}


